{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1367, 9)\n",
      "       3  139  54   0  0.1  25.6  0.402  22  1\n",
      "0      6  119  50  22  176  27.1  1.318  33  1\n",
      "1      9  184  85  15    0  30.0  1.213  49  1\n",
      "2     12   92  62   7  258  27.6  0.926  44  1\n",
      "3      1  113  64  35    0  33.6  0.543  21  1\n",
      "4     11  155  76  28  150  33.3  1.353  51  1\n",
      "5      3  141   0   0    0  30.0  0.761  27  1\n",
      "6      4  123  62   0    0  32.0  0.226  35  1\n",
      "7      0  138   0   0    0  36.3  0.933  25  1\n",
      "8      2  146   0   0    0  27.5  0.240  28  1\n",
      "9     10  101  86  37    0  45.6  1.136  38  1\n",
      "10     7  106  60  24    0  26.5  0.296  29  1\n",
      "11     0  146  70   0    0  37.9  0.334  28  1\n",
      "12     7  161  86   0    0  30.4  0.165  47  1\n",
      "13     2  108  80   0    0  27.0  0.259  52  1\n",
      "14     1  119  86  39  220  45.6  0.808  29  1\n",
      "15     0  107  62  30   74  36.6  0.757  25  1\n",
      "16     2  128  78  37  182  43.3  1.224  31  1\n",
      "17     1  128  48  45  194  40.5  0.613  24  1\n",
      "18     2  146  70  38  360  28.0  0.337  29  1\n",
      "19    14  100  78  25  184  36.6  0.412  46  1\n",
      "20     3  193  70  31    0  34.9  0.241  25  1\n",
      "21     4   95  64   0    0  32.0  0.161  31  1\n",
      "22     5  136  84  41   88  35.0  0.286  35  1\n",
      "23     5  168  64   0    0  32.9  0.135  41  1\n",
      "24     4  115  72   0    0  28.9  0.376  46  1\n",
      "25     8  197  74   0    0  25.9  1.191  39  1\n",
      "26     1  172  68  49  579  42.4  0.702  28  1\n",
      "27     0  138  60  35  167  34.6  0.534  21  1\n",
      "28     3  173  84  33  474  35.7  0.258  22  1\n",
      "29     4  144  82  32    0  38.5  0.554  37  1\n",
      "...   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
      "1337   1  100  66  29  196  32.0  0.444  42  0\n",
      "1338   1  131  64  14  415  23.7  0.389  21  0\n",
      "1339   4  116  72  12   87  22.1  0.463  37  0\n",
      "1340   2  127  58  24  275  27.7  1.600  25  0\n",
      "1341   3   96  56  34  115  24.7  0.944  39  0\n",
      "1342   3   82  70   0    0  21.1  0.389  25  0\n",
      "1343   6  137  61   0    0  24.2  0.151  55  0\n",
      "1344   9   72  78  25    0  31.6  0.280  38  0\n",
      "1345   2  123  48  32  165  42.1  0.520  26  0\n",
      "1346   0  101  62   0    0  21.9  0.336  25  0\n",
      "1347   6  102  90  39    0  35.7  0.674  28  0\n",
      "1348   1  112  72  30  176  34.4  0.528  25  0\n",
      "1349   1  143  84  23  310  42.4  1.076  22  0\n",
      "1350   1  143  74  22   61  26.2  0.256  21  0\n",
      "1351   1   97  68  21    0  27.2  1.095  22  0\n",
      "1352   1   83  68   0    0  18.2  0.624  27  0\n",
      "1353   1  119  88  41  170  45.3  0.507  26  0\n",
      "1354   2   94  68  18   76  26.0  0.561  21  0\n",
      "1355   0  102  64  46   78  40.6  0.496  21  0\n",
      "1356   2  115  64  22    0  30.8  0.421  21  0\n",
      "1357   0   94   0   0    0   0.0  0.256  25  0\n",
      "1358   0  135  94  46  145  40.6  0.284  26  0\n",
      "1359   2   99   0   0    0  22.2  0.108  23  0\n",
      "1360   3   89  74  16   85  30.4  0.551  38  0\n",
      "1361   1   80  74  11   60  30.0  0.527  22  0\n",
      "1362   2  139  75   0    0  25.6  0.167  29  0\n",
      "1363   1   90  68   8    0  24.5  1.138  36  0\n",
      "1364  12  140  85  33    0  37.4  0.244  41  0\n",
      "1365   5  147  75   0    0  29.9  0.434  28  0\n",
      "1366   1   97  70  15    0  18.2  0.147  21  0\n",
      "\n",
      "[1367 rows x 9 columns]\n",
      "       3  139  54   0  0.1  25.6  0.402  22  1\n",
      "0      6  119  50  22  176  27.1  1.318  33  1\n",
      "1      9  184  85  15    0  30.0  1.213  49  1\n",
      "2     12   92  62   7  258  27.6  0.926  44  1\n",
      "3      1  113  64  35    0  33.6  0.543  21  1\n",
      "4     11  155  76  28  150  33.3  1.353  51  1\n",
      "5      3  141   0   0    0  30.0  0.761  27  1\n",
      "6      4  123  62   0    0  32.0  0.226  35  1\n",
      "7      0  138   0   0    0  36.3  0.933  25  1\n",
      "8      2  146   0   0    0  27.5  0.240  28  1\n",
      "9     10  101  86  37    0  45.6  1.136  38  1\n",
      "10     7  106  60  24    0  26.5  0.296  29  1\n",
      "11     0  146  70   0    0  37.9  0.334  28  1\n",
      "12     7  161  86   0    0  30.4  0.165  47  1\n",
      "13     2  108  80   0    0  27.0  0.259  52  1\n",
      "14     1  119  86  39  220  45.6  0.808  29  1\n",
      "15     0  107  62  30   74  36.6  0.757  25  1\n",
      "16     2  128  78  37  182  43.3  1.224  31  1\n",
      "17     1  128  48  45  194  40.5  0.613  24  1\n",
      "18     2  146  70  38  360  28.0  0.337  29  1\n",
      "19    14  100  78  25  184  36.6  0.412  46  1\n",
      "20     3  193  70  31    0  34.9  0.241  25  1\n",
      "21     4   95  64   0    0  32.0  0.161  31  1\n",
      "22     5  136  84  41   88  35.0  0.286  35  1\n",
      "23     5  168  64   0    0  32.9  0.135  41  1\n",
      "24     4  115  72   0    0  28.9  0.376  46  1\n",
      "25     8  197  74   0    0  25.9  1.191  39  1\n",
      "26     1  172  68  49  579  42.4  0.702  28  1\n",
      "27     0  138  60  35  167  34.6  0.534  21  1\n",
      "28     3  173  84  33  474  35.7  0.258  22  1\n",
      "29     4  144  82  32    0  38.5  0.554  37  1\n",
      "...   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
      "1337   1  100  66  29  196  32.0  0.444  42  0\n",
      "1338   1  131  64  14  415  23.7  0.389  21  0\n",
      "1339   4  116  72  12   87  22.1  0.463  37  0\n",
      "1340   2  127  58  24  275  27.7  1.600  25  0\n",
      "1341   3   96  56  34  115  24.7  0.944  39  0\n",
      "1342   3   82  70   0    0  21.1  0.389  25  0\n",
      "1343   6  137  61   0    0  24.2  0.151  55  0\n",
      "1344   9   72  78  25    0  31.6  0.280  38  0\n",
      "1345   2  123  48  32  165  42.1  0.520  26  0\n",
      "1346   0  101  62   0    0  21.9  0.336  25  0\n",
      "1347   6  102  90  39    0  35.7  0.674  28  0\n",
      "1348   1  112  72  30  176  34.4  0.528  25  0\n",
      "1349   1  143  84  23  310  42.4  1.076  22  0\n",
      "1350   1  143  74  22   61  26.2  0.256  21  0\n",
      "1351   1   97  68  21    0  27.2  1.095  22  0\n",
      "1352   1   83  68   0    0  18.2  0.624  27  0\n",
      "1353   1  119  88  41  170  45.3  0.507  26  0\n",
      "1354   2   94  68  18   76  26.0  0.561  21  0\n",
      "1355   0  102  64  46   78  40.6  0.496  21  0\n",
      "1356   2  115  64  22    0  30.8  0.421  21  0\n",
      "1357   0   94   0   0    0   0.0  0.256  25  0\n",
      "1358   0  135  94  46  145  40.6  0.284  26  0\n",
      "1359   2   99   0   0    0  22.2  0.108  23  0\n",
      "1360   3   89  74  16   85  30.4  0.551  38  0\n",
      "1361   1   80  74  11   60  30.0  0.527  22  0\n",
      "1362   2  139  75   0    0  25.6  0.167  29  0\n",
      "1363   1   90  68   8    0  24.5  1.138  36  0\n",
      "1364  12  140  85  33    0  37.4  0.244  41  0\n",
      "1365   5  147  75   0    0  29.9  0.434  28  0\n",
      "1366   1   97  70  15    0  18.2  0.147  21  0\n",
      "\n",
      "[1367 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fitdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1608fd96ed69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1608fd96ed69>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, fitdata)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfitdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0malldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#Population base on {w,b}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fitdata'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use ('ggplot')\n",
    "import pandas \n",
    "\n",
    "filename = 'ModelData.csv' #Importation of Data \n",
    "trainingdata = pandas.read_csv(filename)\n",
    "print(trainingdata.shape)\n",
    "print(trainingdata)  \n",
    "\n",
    "\n",
    "print(trainingdata)\n",
    "\n",
    "X = trainingdata.values[:, :2]\n",
    "Y = trainingdata.values[:, 8]\n",
    "filename2 = 'Testdata.csv'\n",
    "TTdata = pandas.read_csv(filename2)\n",
    "XT = TTdata.values[:, :2]\n",
    "YT = TTdata.values[:, :8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, visualization=True):    #An Intition class for the classifier \n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:          #visualisation of the classifier framework on a grid\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(2,2,1)\n",
    "            #self.ax.subplot(2, 2, i + 1)\n",
    "            #self.ax.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    \n",
    "            \n",
    "    def train(self, fitdata):         #Building Model using the training data \n",
    "        fitdata = np.array([],[])\n",
    "        self.fitdata = fitdata \n",
    "        alldata = []\n",
    "        Group = {} #Population base on {w,b}\n",
    "    \n",
    "\n",
    "    \n",
    "        transforms = [[1,-1],\n",
    "                     [1,1],\n",
    "                     [-1,1],\n",
    "                      [-1,-1]]\n",
    "                  \n",
    "        for yi in self.fitdata:\n",
    "            for featureset in self.fitdata[yi]:\n",
    "                for feature in featureset:\n",
    "                    alldata.append(feature)\n",
    "            \n",
    "        self.max_feature_value = X[:, 0].max() + 1    #Search processs\n",
    "        self.min_feature_value = X[:, 0].min() - 1 \n",
    "        alldata = None\n",
    "        h=5\n",
    "        x_min = X[:, 0].min() - 1\n",
    "        x_max = X[:, 0].max() + 1\n",
    "    \n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "     \n",
    "    \n",
    "        stepsize = [self.max_feature_value* 0.05]\n",
    "    \n",
    "        b_range = 5\n",
    "        b_multiple = 5\n",
    "        lastest_optimum = self.max_feature_value*10\n",
    "    \n",
    "        for step in stepsize:                           #Optimization process\n",
    "            w = np.array([lastest_optimum,lastest_optimum])\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_multiple), self.max_feature_value*b_multiple, step*b_multiple):\n",
    "                    for transformation in transforms: \n",
    "                        wt = w*transformation\n",
    "                        found_option = True\n",
    "                  \n",
    "                        for i in self.fitdata:\n",
    "                            for xi in self.fitdata[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(wt,xi)+b) >=1:\n",
    "                                    found_option = False\n",
    "                                  #break\n",
    "                            \n",
    "                  \n",
    "                        if found_option:\n",
    "                              Group[np.linalg.norm(wt)] = [wt,b]\n",
    "                  \n",
    "                if w[0] < 0:\n",
    "                          optimized = True \n",
    "                          print('Processed Optimized')\n",
    "                  \n",
    "                else:\n",
    "                          w = w - step \n",
    "            norms = sorted ([n for n in Group]) #Sorted list of the magnitudes \n",
    "            Group_choice = Group[norms[0]]\n",
    "            self.w = Group_choice[0]\n",
    "            self.b = Group_choice[1]\n",
    "            latest_optimum = Group_choice[0][0]+step*2\n",
    "        \n",
    "        for i in self.fitdata:\n",
    "            for xi in self.fitdata[i]:\n",
    "                yi=i\n",
    "                print(xi,':',yi*(np.dot(self.w,xi)+self.b))\n",
    "            \n",
    "    def predict(self,features):                                                   #Prediction of unlabelled data vs the model built \n",
    "        classification = np.sign(np.dot(np.array(features), self.w)+self.b)\n",
    "        if classification !=0 and self.visualization:\n",
    "            \n",
    "            self.ax.scatter(features[:,0], features[:,1], marker='*', c=self.colors[classification])\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def visualize(self):                                             #Displays points of each classs\n",
    "        for i, clf in enumerate((SVM().train)):\n",
    "    \n",
    "            # Plot the decision boundary. For that, we will assign a color to each\n",
    "            # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "            self.ax.subplot(2, 2, i + 1)\n",
    "            self.ax.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "            Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "            # Put the result into a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            self.ax.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "            # Plot also the training points\n",
    "            self.ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "            \n",
    "            self.ax.xlim(xx.min(), xx.max())\n",
    "            self.ax.ylim(yy.min(), yy.max())\n",
    "            self.ax.xticks(())\n",
    "            self.ax.yticks(())\n",
    "            \n",
    "        #[[self.ax.scatter(X[:, 0], X[:, 1],color=self.colors[i])for x in labels[i]] for i in labels]\n",
    "        \n",
    "                         \n",
    "        def hyperplane(x,w,b,c): #Gives the hyperplane value  c=X.W+b , decision boundary, positive or negative,for the graph\n",
    "                  calc = (-w[0]*x-b+c)/w[1]\n",
    "                  return calc\n",
    "                  \n",
    "        datarange = (self.min_feature_value*9.0,self.max_feature_value*1.1) \n",
    "        hyper_x_max = datarange[1]\n",
    "        hyper_x_min = datarange[0]\n",
    "                  \n",
    "                  \n",
    "        postivesv1 = hyperplane(hyper_x_min, self.w, self.b, 1)#positive support vector, is going to be y, (w.X+b) = 1\n",
    "        postivesv2 = hyperplane(hyper_x_max, self.w, self.b, 1)#second point       \n",
    "        self.ax.plot([hyper_x_min,hyper_x_max], [postivesv1, postivesv2], 'k') \n",
    "                  \n",
    "        negativesv1 = hyperplane(hyper_x_min, self.w, self.b, -1)#negative support vector, (W.X+b) = -1\n",
    "        negativesv2 = hyperplane(hyper_x_max, self.w, self.b, -1)#second point       \n",
    "        self.ax.plot([hyper_x_min,hyper_x_max], [negativesv1, negativesv2], 'k')\n",
    "                  \n",
    "        decisionsv1 = hyperplane(hyper_x_min, self.w, self.b, 0)#decision margin, (W.X+b) = 0       \n",
    "        decisionsv2 = hyperplane(hyper_x_max, self.w, self.b, 0)#second point       \n",
    "        self.ax.plot([hyper_x_min,hyper_x_max], [decisionsv1, decisionsv2], 'k--')   \n",
    "        plt.show()\n",
    "                  \n",
    "labels = {-1:X[:,0], 1:X[:,1]}                 \n",
    "classifier = SVM.train(fitdata = labels, self = classifier)  \n",
    "trainingdata.astype(int)\n",
    "SVM.visualize(classifier)\n",
    "#Dset = {-1:trainingdata[:,1:7],1:trainingdata[:,8]}\n",
    "#labels = {-1:X[:,0], 1:X[:,1]}\n",
    "#fit = classifier.train(fitdata = labels)\n",
    "#classifier.visualize()\n",
    "                  \n",
    "predictTest = TTdata.values[:, :2] \n",
    "\n",
    "for f in predictTest:\n",
    "    SVM.predict(f)\n",
    "    \n",
    "    \n",
    "SVM.visualize(classifier)\n",
    "                  \n",
    "    \n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
